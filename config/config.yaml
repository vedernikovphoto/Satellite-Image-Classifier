project_name: 'Planets'                    
experiment_name: 'experiment1'
num_classes: 17                           
n_epochs: 10
accelerator: 'gpu'
device: 0
seed: 42
log_every_n_steps: 20
monitor_metric: 'val_f1'
monitor_mode: 'max'

model_kwargs:
  model_name: 'efficientnet_b0'
  pretrained: true

optimizer: 'torch.optim.AdamW'
optimizer_kwargs:
  lr: 1e-3
  weight_decay: 1e-5

scheduler: 'torch.optim.lr_scheduler.CosineAnnealingLR'
scheduler_kwargs:
  T_max: 10
  eta_min: 1e-5

losses:
  - name: 'bce'
    weight: 1.0
    loss_fn: 'torch.nn.BCEWithLogitsLoss'
    loss_kwargs: {}

data_config:
  data_path: 'data/planet/planet'        # Updated path to your training images
  batch_size: 64
  n_workers: 4
  train_size: 0.8
  width: 224
  height: 224

augmentation_params:
  hue_shift_limit: 20
  sat_shift_limit: 30
  val_shift_limit: 20
  brightness_limit: 0.2
  contrast_limit: 0.2

label_encoder:
  haze: 0
  primary: 1
  agriculture: 2
  clear: 3
  water: 4
  habitation: 5
  road: 6
  cultivation: 7
  slash_burn: 8
  cloudy: 9
  partly_cloudy: 10
  conventional_mine: 11
  bare_ground: 12
  artisinal_mine: 13
  blooming: 14
  selective_logging: 15
  blow_down: 16